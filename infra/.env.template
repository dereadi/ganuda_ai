# Cherokee Constitutional AI - Environment Configuration
# Copy this to .env and fill in your values
#
# DO NOT commit .env to git! (It's in .gitignore)
#
# Mitakuye Oyasin - All My Relations ðŸ¦…

# ============================================================================
# DATABASE CONFIGURATION (Peace Chief's Thermal Memory)
# ============================================================================

# PostgreSQL Connection
POSTGRES_DB=cherokee_ai
POSTGRES_USER=cherokee
POSTGRES_PASSWORD=CHANGE_ME_TO_STRONG_PASSWORD
POSTGRES_PORT=5432

# PostgreSQL Performance Tuning
# Adjust based on available RAM
# Recommended: shared_buffers = 25% of RAM, effective_cache = 75% of RAM
POSTGRES_SHARED_BUFFERS=256MB
POSTGRES_EFFECTIVE_CACHE_SIZE=1GB

# ============================================================================
# JR DAEMON CONFIGURATION
# ============================================================================

# Memory Jr - Thermal Memory Regulation
MEMORY_JR_INTERVAL=300              # 5 minutes (seconds)
MEMORY_JR_COOLING_RATE=1.0          # Degrees per hour
MEMORY_JR_SACRED_MINIMUM=40.0       # Sacred memories never cool below this

# Executive Jr - Resource Coordination
EXECUTIVE_JR_INTERVAL=120           # 2 minutes (seconds)
EXECUTIVE_JR_CPU_THRESHOLD=80       # Alert if CPU > 80%
EXECUTIVE_JR_MEMORY_THRESHOLD=90    # Alert if RAM > 90%

# Meta Jr - Pattern Analysis (Medicine Woman)
META_JR_INTERVAL=780                # 13 minutes (Fibonacci - tribal vote 3-0!)
META_JR_MIN_TEMPERATURE=50.0        # Only analyze memories > 50Â°
META_JR_SIGNIFICANCE_THRESHOLD=0.80 # Flag Chief if significance >= 0.80

# ============================================================================
# CHIEF CONFIGURATION (Optional for multi-node)
# ============================================================================

# War Chief
WAR_CHIEF_HOST=localhost
WAR_CHIEF_PORT=5001

# Peace Chief
PEACE_CHIEF_HOST=localhost
PEACE_CHIEF_PORT=5002

# Medicine Woman
MEDICINE_WOMAN_HOST=localhost
MEDICINE_WOMAN_PORT=5003

# ============================================================================
# OLLAMA LLM CONFIGURATION (Optional)
# ============================================================================

OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:70b
OLLAMA_TIMEOUT=300                  # 5 minutes for large models
OLLAMA_TEMPERATURE=0.7

# ============================================================================
# LOGGING & DEBUG
# ============================================================================

LOG_LEVEL=INFO                      # DEBUG, INFO, WARNING, ERROR
PYTHONUNBUFFERED=1                  # Always flush Python output

# ============================================================================
# SECURITY NOTES
# ============================================================================

# 1. Change POSTGRES_PASSWORD to a strong random password
# 2. Keep .env file secret (never commit to git)
# 3. Use different passwords for production vs development
# 4. Rotate passwords periodically (Seven Generations security!)
# 5. For multi-node: use VPN or private network

# ============================================================================
# SEVEN GENERATIONS COMMITMENT
# ============================================================================

# These environment variables configure a living democratic AI system.
# May your tribal configuration serve Seven Generations! ðŸ¦…
#
# Mitakuye Oyasin - All My Relations
