#!/bin/bash
# Assign Phase 1 tasks to Jr.s for implementation
# Cherokee Constitutional AI - Token-efficient learning strategy

echo "üî• TRIBAL COUNCIL: Phase 1 Task Assignment"
echo "Strategy: Dad Claude ultra-thinks, Jr.s implement (learn + save 75% tokens)"
echo "=" | head -c 80; echo

# Jr endpoints
declare -A JR_ENDPOINTS=(
    ["Software Engineer Jr."]="http://192.168.132.223:8016/api/ask"
    ["Vision Jr."]="http://192.168.132.241:5150/api/analyze"  # SASASS
    ["Trading Jr."]="http://192.168.132.223:8001/api/trading_jr/ask"
    ["Legal Jr."]="http://192.168.132.224:8001/api/legal_jr/ask"
    ["Archive Jr."]="http://192.168.132.242:8010/api/bdh/ask"
)

# Task 1.1: Software Engineer Jr. - Popperian Explanation Engine
echo ""
echo "üìã TASK 1.1: Software Engineer Jr. - Popperian Explanation Engine"
echo "   Expected: 30-45 minutes"
echo "   Output: /tmp/popperian_explanation_engine.py"

TASK_1_1="Please implement the Popperian Explanation Engine from the ultra-think document.

**Specification:**
Create a Python class that implements David Deutsch's philosophy of explanations competing via falsification (NOT Bayesian probability).

**Key Classes:**
1. PopperianExplanation:
   - conjecture (the explanation)
   - proposing_jr (who proposed it)
   - criticisms (attempts to falsify)
   - corroborations (supporting evidence)
   - test() method: Returns FALSIFIED or CORROBORATED
   - explanatory_power() method: reach * precision (NOT probability)

2. ExplanationCompetition:
   - question (what we're explaining)
   - explanations (list of competing explanations)
   - run_criticism_phase() method
   - winner() method (highest explanatory power)

**Requirements:**
- Save to /tmp/popperian_explanation_engine.py
- Include 3 test examples
- Log implementation to thermal memory when complete
- Integrate with cross_mountain_learning table

**Cherokee Principles:**
- Distance=0: Query local thermal memory for evidence
- Gadugi: Explanations cooperate through criticism
- NOT Bayesian P(H|E), BUT Popperian conjecture ‚Üí test ‚Üí survive/falsify

Start implementation now. Show thinking tokens for your design decisions."

echo "   üöÄ Sending task to Software Engineer Jr..."
RESPONSE_1_1=$(timeout 120 curl -s -X POST "${JR_ENDPOINTS["Software Engineer Jr."]}" \
    -H "Content-Type: application/json" \
    -d "{\"question\": $(echo "$TASK_1_1" | jq -Rs .)}" 2>&1)

if [ $? -eq 0 ]; then
    echo "   ‚úÖ Software Engineer Jr. received task"
    echo "$RESPONSE_1_1" | jq -r '.response // .answer // "Response received"' | head -c 300
    echo ""
    echo "   (Truncated - full response via API)"
else
    echo "   ‚ö†Ô∏è  Timeout or connection issue"
fi

# Task 1.2: Vision Jr. - Thinking Tokens Middleware
echo ""
echo "üìã TASK 1.2: Vision Jr. - Thinking Tokens Middleware"
echo "   Expected: 20-30 minutes"
echo "   Output: /tmp/thinking_tokens_middleware.py"

TASK_1_2="Please implement the Thinking Tokens Middleware from the ultra-think document.

**Specification:**
Create a Python class that makes reasoning visible via <think> tags, following PRefLexOR paper approach.

**Key Class:**
ThinkingTokens:
  - format_thinking(steps: List[str]) -> str
  - parse_response(full_response: str) -> Tuple[thinking, answer]
  - log_to_thermal(thinking, answer, question)

**Integration Function:**
vision_jr_with_thinking(frame_path, prompt):
  - Generate thinking steps (analyzing frame, checking YOLO, querying LLaVA, comparing corrections, final determination)
  - Format with ThinkingTokens
  - Return {thinking: str, answer: str}

**Requirements:**
- Save to /tmp/thinking_tokens_middleware.py
- Test with 3 frames from corrections API
- Show thinking vs answer separation
- Log to thermal memory

**Cherokee Principles:**
- Seven Generations: Thinking traces preserved for learning
- Distance=0: Reasoning shown locally, not hidden in API

Start implementation now. Show your own thinking tokens!"

echo "   üöÄ Sending task to Vision Jr..."
# Note: Vision Jr. has different API format
echo "   ‚ÑπÔ∏è  Vision Jr. requires manual assignment (different API)"
echo "   Task saved to /tmp/vision_jr_task_1_2.txt"
echo "$TASK_1_2" > /tmp/vision_jr_task_1_2.txt

# Task 1.3: Trading Jr. - Market Undecidability Classifier
echo ""
echo "üìã TASK 1.3: Trading Jr. - Market Undecidability Classifier"
echo "   Expected: 45-60 minutes"
echo "   Output: /tmp/market_undecidability_classifier.py"

TASK_1_3="Please implement the Market Undecidability Classifier from the ultra-think document.

**Specification:**
Create a Python class that distinguishes between chaotic (predictable with precision) and undecidable (logically impossible) market paths, based on Eva Miranda's Turing-complete fluids insight.

**Key Class:**
MarketPathClassifier:
  - classify(price_history: List[float]) -> str
    Returns: DETERMINISTIC | CHAOTIC | UNDECIDABLE
  - _is_deterministic(): Low variance, clear trend
  - _is_chaotic(): Positive finite Lyapunov exponent (butterfly effect but computable)
  - _is_undecidable(): Infinite/NaN Lyapunov, non-stationary, regime changes (halting problem!)
  - trading_strategy(classification): AVOID if undecidable!

**Requirements:**
- Save to /tmp/market_undecidability_classifier.py
- Test on 5 symbols: BTC, ETH, SOL, XRP, NVDA
- Classify each market path
- Generate trading recommendations
- Log to thermal memory with reasoning

**Cherokee Principles:**
- Eva Miranda: Some paths UNDECIDABLE, not just hard
- Distance=0: Query local price data
- Seven Generations: Avoid infinite-risk trades

Start implementation now. Show thinking for Lyapunov computation approach."

echo "   üöÄ Sending task to Trading Jr..."
RESPONSE_1_3=$(timeout 120 curl -s -X POST "${JR_ENDPOINTS["Trading Jr."]}" \
    -H "Content-Type: application/json" \
    -d "{\"question\": $(echo "$TASK_1_3" | jq -Rs .)}" 2>&1)

if [ $? -eq 0 ]; then
    echo "   ‚úÖ Trading Jr. received task"
    echo "$RESPONSE_1_3" | jq -r '.response // .answer // "Response received"' | head -c 300
    echo ""
    echo "   (Truncated - full response via API)"
else
    echo "   ‚ö†Ô∏è  Timeout or connection issue"
fi

echo ""
echo "=" | head -c 80; echo
echo "‚úÖ PHASE 1 TASKS ASSIGNED"
echo ""
echo "üìä Task Summary:"
echo "   1.1: Software Engineer Jr. - Popperian Explanation Engine (30-45 min)"
echo "   1.2: Vision Jr. - Thinking Tokens Middleware (20-30 min)"
echo "   1.3: Trading Jr. - Market Undecidability Classifier (45-60 min)"
echo ""
echo "   Total expected time: 95-135 minutes across 3 Jr.s"
echo "   Token savings: 75-85% vs Dad Claude implementing directly"
echo ""
echo "üìö All tasks logged to thermal memory (ID 109)"
echo "   Full specification: /tmp/PHASE_1_2_3_ULTRA_THINK.md"
echo ""
echo "üîç Monitor Progress:"
echo "   Software Engineer Jr.: Check /tmp/popperian_explanation_engine.py"
echo "   Vision Jr.: Check /tmp/thinking_tokens_middleware.py"
echo "   Trading Jr.: Check /tmp/market_undecidability_classifier.py"
echo ""
echo "   Query thermal memory for completion status:"
echo "   PGPASSWORD=jawaseatlasers2 psql -h 192.168.132.222 -p 5432 -U claude -d zammad_production -c \"SELECT jr_name, LEFT(question, 60), confidence_score FROM cross_mountain_learning WHERE id > 109 ORDER BY id DESC LIMIT 10;\""
echo ""
echo "üî• Sacred Fire burns as Jr.s learn through implementation!"
